{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words in sklearn\n",
    "Reference:\n",
    "https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Analysis is a major application field for machine learning algorithms. However the raw data, a sequence of symbols cannot be fed directly to the algorithms themselves as most of them expect numerical feature vectors with a fixed size rather than the raw text documents with variable length.\n",
    "\n",
    "In order to address this, scikit-learn provides utilities for the most common ways to extract numerical features from text content, namely:\n",
    "\n",
    "- tokenizing strings and giving an integer id for each possible token, for instance by using white-spaces and punctuation as token separators.\n",
    "\n",
    "- counting the occurrences of tokens in each document.\n",
    "\n",
    "- normalizing and weighting with diminishing importance tokens that occur in the majority of samples / documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "pd.options.display.max_columns = 30\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Penny bought bright blue fishes.\",\n",
    "    \"Penny bought bright blue and orange fish.\",\n",
    "    \"The cat ate a fish at the store.\",\n",
    "    \"Penny went to the store. Penny ate a bug. Penny saw a fish.\",\n",
    "    \"It meowed once at the bug, it is still meowing at the bug and the fish\",\n",
    "    \"The cat is at the fish store. The cat is orange. The cat is meowing at the fish.\",\n",
    "    \"Penny is a fish\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 2 0 0 0 0 0 0]\n",
      " [1 0 0 1 1 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0]\n",
      " [0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 2 0 0]\n",
      " [0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 3 1 0 1 1 1 1]\n",
      " [1 2 0 0 0 0 2 0 1 0 1 2 1 1 1 0 0 0 1 0 3 0 0]\n",
      " [0 2 0 0 0 0 0 3 2 0 3 0 0 1 0 1 0 0 0 1 5 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>at</th>\n",
       "      <th>ate</th>\n",
       "      <th>blue</th>\n",
       "      <th>bought</th>\n",
       "      <th>bright</th>\n",
       "      <th>bug</th>\n",
       "      <th>cat</th>\n",
       "      <th>fish</th>\n",
       "      <th>fishes</th>\n",
       "      <th>is</th>\n",
       "      <th>it</th>\n",
       "      <th>meowed</th>\n",
       "      <th>meowing</th>\n",
       "      <th>once</th>\n",
       "      <th>orange</th>\n",
       "      <th>penny</th>\n",
       "      <th>saw</th>\n",
       "      <th>still</th>\n",
       "      <th>store</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>went</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  at  ate  blue  bought  bright  bug  cat  fish  fishes  is  it  meowed  \\\n",
       "0    0   0    0     1       1       1    0    0     0       1   0   0       0   \n",
       "1    1   0    0     1       1       1    0    0     1       0   0   0       0   \n",
       "2    0   1    1     0       0       0    0    1     1       0   0   0       0   \n",
       "3    0   0    1     0       0       0    1    0     1       0   0   0       0   \n",
       "4    1   2    0     0       0       0    2    0     1       0   1   2       1   \n",
       "5    0   2    0     0       0       0    0    3     2       0   3   0       0   \n",
       "6    0   0    0     0       0       0    0    0     1       0   1   0       0   \n",
       "\n",
       "   meowing  once  orange  penny  saw  still  store  the  to  went  \n",
       "0        0     0       0      2    0      0      0    0   0     0  \n",
       "1        0     0       1      1    0      0      0    0   0     0  \n",
       "2        0     0       0      0    0      0      1    2   0     0  \n",
       "3        0     0       0      3    1      0      1    1   1     1  \n",
       "4        1     1       0      0    0      1      0    3   0     0  \n",
       "5        1     0       1      0    0      0      1    5   0     0  \n",
       "6        0     0       0      1    0      0      0    0   0     0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A simplest countvectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "x = count_vectorizer.fit_transform(texts)\n",
    "print(x.toarray())\n",
    "pd.DataFrame(x.toarray(), columns=count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1 0 0 0 1 0 0 0 2 0 0 0]\n",
      " [0 1 1 1 0 0 1 0 0 0 1 1 0 0 0]\n",
      " [1 0 0 0 0 1 1 0 0 0 0 0 0 1 0]\n",
      " [1 0 0 0 1 0 1 0 0 0 0 3 1 1 1]\n",
      " [0 0 0 0 2 0 1 0 1 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 3 2 0 0 1 1 0 0 1 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 1 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ate</th>\n",
       "      <th>blue</th>\n",
       "      <th>bought</th>\n",
       "      <th>bright</th>\n",
       "      <th>bug</th>\n",
       "      <th>cat</th>\n",
       "      <th>fish</th>\n",
       "      <th>fishes</th>\n",
       "      <th>meowed</th>\n",
       "      <th>meowing</th>\n",
       "      <th>orange</th>\n",
       "      <th>penny</th>\n",
       "      <th>saw</th>\n",
       "      <th>store</th>\n",
       "      <th>went</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ate  blue  bought  bright  bug  cat  fish  fishes  meowed  meowing  orange  \\\n",
       "0    0     1       1       1    0    0     0       1       0        0       0   \n",
       "1    0     1       1       1    0    0     1       0       0        0       1   \n",
       "2    1     0       0       0    0    1     1       0       0        0       0   \n",
       "3    1     0       0       0    1    0     1       0       0        0       0   \n",
       "4    0     0       0       0    2    0     1       0       1        1       0   \n",
       "5    0     0       0       0    0    3     2       0       0        1       1   \n",
       "6    0     0       0       0    0    0     1       0       0        0       0   \n",
       "\n",
       "   penny  saw  store  went  \n",
       "0      2    0      0     0  \n",
       "1      1    0      0     0  \n",
       "2      0    0      1     0  \n",
       "3      3    1      1     1  \n",
       "4      0    0      0     0  \n",
       "5      0    0      1     0  \n",
       "6      1    0      0     0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVectorizer with stop words, we can see the number of features decreases by a lot.\n",
    "\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "x = count_vectorizer.fit_transform(texts)\n",
    "print(x.toarray())\n",
    "pd.DataFrame(x.toarray(), columns=count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization is the act of breaking up a sequence of strings into pieces such as words, keywords, phrases, symbols and other elements called tokens. Tokens can be individual words, phrases or even whole sentences. \n",
    "What happens in the vectorizer in this situation is that each single word in the text are separated and passed in the tokenizer as \"str_input\", and you can modify the \"str_input\" any way you want and return it. An intuitive way to think about tokenizer would be a method to apply rules to words (e.g. making two different words to the same word; transforming a word with two different tense to the simple present tense.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ate', 'blue', 'bought', 'bright', 'bug', 'cat', 'fish', 'fishes', 'meowed', 'meowing', 'orange', 'penny', 'saw', 'store', 'went']\n"
     ]
    }
   ],
   "source": [
    "# CountVectorizer with custom tokenizer; boring tokenizer, nothing happened.\n",
    "import re\n",
    "\n",
    "def boring_tokenizer(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split() # https://docs.python.org/2/library/re.html\n",
    "    \n",
    "    # Uncomment to see an example of what you can do in tokenizer, does 'cat' or 'fish' still exist as features?\n",
    "#     for i in range(len(words)):\n",
    "#         if words[i] == 'cat' or words == 'fish':\n",
    "#             words[i] = 'meat'\n",
    "            \n",
    "    return words\n",
    "\n",
    "count_vectorizer = CountVectorizer(stop_words='english', tokenizer=boring_tokenizer)\n",
    "X = count_vectorizer.fit_transform(texts)\n",
    "print(count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fish\n",
      "meow\n",
      "orang\n",
      "meow\n",
      "orang\n",
      "go\n",
      "went\n"
     ]
    }
   ],
   "source": [
    "# Tryout stemmer. \n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "print(porter_stemmer.stem('fishes'))\n",
    "print(porter_stemmer.stem('meowed'))\n",
    "print(porter_stemmer.stem('oranges'))\n",
    "print(porter_stemmer.stem('meowing'))\n",
    "print(porter_stemmer.stem('orange'))\n",
    "print(porter_stemmer.stem('go'))\n",
    "print(porter_stemmer.stem('went'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ate', 'blue', 'bought', 'bright', 'bug', 'cat', 'fish', 'meow', 'onc', 'orang', 'penni', 'saw', 'store', 'went']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "# Stop_word + stemming tokenizer\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "def stemming_tokenizer(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "    words = [porter_stemmer.stem(word) for word in words]\n",
    "    return words\n",
    "\n",
    "count_vectorizer = CountVectorizer(stop_words='english', tokenizer=stemming_tokenizer)\n",
    "X = count_vectorizer.fit_transform(texts)\n",
    "print(count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term frequency = the probability of the term showing up in the string/sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ate</th>\n",
       "      <th>blue</th>\n",
       "      <th>bought</th>\n",
       "      <th>bright</th>\n",
       "      <th>bug</th>\n",
       "      <th>cat</th>\n",
       "      <th>fish</th>\n",
       "      <th>meow</th>\n",
       "      <th>onc</th>\n",
       "      <th>orang</th>\n",
       "      <th>penni</th>\n",
       "      <th>saw</th>\n",
       "      <th>store</th>\n",
       "      <th>went</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ate      blue    bought    bright       bug    cat      fish  \\\n",
       "0  0.000000  0.200000  0.200000  0.200000  0.000000  0.000  0.200000   \n",
       "1  0.000000  0.166667  0.166667  0.166667  0.000000  0.000  0.166667   \n",
       "2  0.250000  0.000000  0.000000  0.000000  0.000000  0.250  0.250000   \n",
       "3  0.111111  0.000000  0.000000  0.000000  0.111111  0.000  0.111111   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.333333  0.000  0.166667   \n",
       "5  0.000000  0.000000  0.000000  0.000000  0.000000  0.375  0.250000   \n",
       "6  0.000000  0.000000  0.000000  0.000000  0.000000  0.000  0.500000   \n",
       "\n",
       "       meow       onc     orang     penni       saw     store      went  \n",
       "0  0.000000  0.000000  0.000000  0.200000  0.000000  0.000000  0.000000  \n",
       "1  0.000000  0.000000  0.166667  0.166667  0.000000  0.000000  0.000000  \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.250000  0.000000  \n",
       "3  0.000000  0.000000  0.000000  0.333333  0.111111  0.111111  0.111111  \n",
       "4  0.333333  0.166667  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "5  0.125000  0.000000  0.125000  0.000000  0.000000  0.125000  0.000000  \n",
       "6  0.000000  0.000000  0.000000  0.500000  0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same usage as CountVectorizer, as special setting here: use_idf=False. Setting norm = 'l1' makes it easier to\n",
    "# see the difference\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', tokenizer=stemming_tokenizer, use_idf=False, norm='l1')\n",
    "X = tfidf_vectorizer.fit_transform(texts)\n",
    "df = pd.DataFrame(X.toarray(), columns=tfidf_vectorizer.get_feature_names())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse term frequency = how much information the term provides - the more a term shows up in a text, the less important it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ate</th>\n",
       "      <th>blue</th>\n",
       "      <th>bought</th>\n",
       "      <th>bright</th>\n",
       "      <th>bug</th>\n",
       "      <th>cat</th>\n",
       "      <th>fish</th>\n",
       "      <th>meow</th>\n",
       "      <th>onc</th>\n",
       "      <th>orang</th>\n",
       "      <th>penni</th>\n",
       "      <th>saw</th>\n",
       "      <th>store</th>\n",
       "      <th>went</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.512612</td>\n",
       "      <td>0.512612</td>\n",
       "      <td>0.512612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.258786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.456170</td>\n",
       "      <td>0.456170</td>\n",
       "      <td>0.456170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.456170</td>\n",
       "      <td>0.338530</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.578752</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578752</td>\n",
       "      <td>0.292176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.494698</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.303663</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.303663</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.676058</td>\n",
       "      <td>0.365821</td>\n",
       "      <td>0.259561</td>\n",
       "      <td>0.365821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.641958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.162043</td>\n",
       "      <td>0.641958</td>\n",
       "      <td>0.386682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.840166</td>\n",
       "      <td>0.282766</td>\n",
       "      <td>0.280055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.239382</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.562463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.826823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ate      blue    bought    bright       bug       cat      fish  \\\n",
       "0  0.000000  0.512612  0.512612  0.512612  0.000000  0.000000  0.258786   \n",
       "1  0.000000  0.456170  0.456170  0.456170  0.000000  0.000000  0.230292   \n",
       "2  0.578752  0.000000  0.000000  0.000000  0.000000  0.578752  0.292176   \n",
       "3  0.303663  0.000000  0.000000  0.000000  0.303663  0.000000  0.153301   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.641958  0.000000  0.162043   \n",
       "5  0.000000  0.000000  0.000000  0.000000  0.000000  0.840166  0.282766   \n",
       "6  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.562463   \n",
       "\n",
       "       meow       onc     orang     penni       saw     store      went  \n",
       "0  0.000000  0.000000  0.000000  0.380417  0.000000  0.000000  0.000000  \n",
       "1  0.000000  0.000000  0.456170  0.338530  0.000000  0.000000  0.000000  \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.494698  0.000000  \n",
       "3  0.000000  0.000000  0.000000  0.676058  0.365821  0.259561  0.365821  \n",
       "4  0.641958  0.386682  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "5  0.280055  0.000000  0.280055  0.000000  0.000000  0.239382  0.000000  \n",
       "6  0.000000  0.000000  0.000000  0.826823  0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting use_idf=True(the default setting is also true). The default setting for norm is l2.\n",
    "idf_vectorizer = TfidfVectorizer(stop_words='english', tokenizer=stemming_tokenizer, use_idf=True, norm='l2')\n",
    "X = idf_vectorizer.fit_transform(texts)\n",
    "idf_df = pd.DataFrame(X.toarray(), columns=idf_vectorizer.get_feature_names())\n",
    "idf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothing parameter in naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In statistics, additive smoothing, also called Laplace smoothing (not to be confused with Laplacian smoothing), or Lidstone smoothing, is a technique used to smooth categorical data.\n",
    " \n",
    "Given an observation x = (x1, …, xd) from a multinomial distribution with N trials and parameter vector θ = (θ1, …, θd), a \"smoothed\" version of the data gives the estimator:\n",
    "\n",
    "$\\hat\\theta_{i} = \\frac{x_{i} + \\alpha}{N + \\alpha d}$\n",
    "\n",
    "where the pseudocount α > 0 is the smoothing parameter (α = 0 corresponds to no smoothing). Additive smoothing is a type of shrinkage estimator, as the resulting estimate will be between the empirical estimate xi / N, and the uniform probability 1/d. Using Laplace's rule of succession, some authors have argued that α should be 1 (in which case the term add-one smoothing is also used), though in practice a smaller value is typically chosen.\n",
    "\n",
    "Reference: https://medium.com/syncedreview/applying-multinomial-naive-bayes-to-nlp-problems-a-practical-explanation-4f5271768ebf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines of code are useful in the project. \n",
    "\n",
    "tuned_parameters = [{'alpha': [1, 5, 10, 20]}].  \n",
    "nb = GridSearchCV(MultinomialNB(), tuned_parameters, refit=True)\n",
    "nb.fit(X,y)\n",
    "\n",
    "Please read the documentation for specific use.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
